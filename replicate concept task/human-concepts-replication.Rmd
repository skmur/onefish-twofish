---
title: "Replicating Latent Diversity in Human Concepts paper"
output: html_notebook
---

```{r}
library(ggplot2)
library(ggbiplot)
library(dplyr)
library(tidyr)
library(lme4)
library(lmerTest)
library(Rtsne)
library(RColorBrewer)
library(colorRamps)
library(patchwork)
library(ggpubr)
library(scales)
library(lsa)
library(stringr)
```


```{r}
theme <- theme_bw() +
  theme(plot.title = element_text(face = "bold", hjust = 0.5),
        text = element_text(size = 20),
        axis.title.x = element_text(face = "bold"),
        axis.title.y = element_text(face = "bold"),
        legend.title = element_text(face = "bold"),
        panel.grid.minor.x = element_blank(),
        panel.grid.major.x = element_blank(), aspect.ratio = 1,
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = .1))

theme_set(theme)

custom_colors <- c("#b074ff", "#59b8ff", "#ff9240",
                   "#ff0022", "#ff00a1", "#e800ff", "#5a00ff", "#007fff", "#00f4ff", "#00ff00", "#ff9a00", "#ff5100",
                   "#9b0000", "#b40050", "#7e00a8", "#3800a6", "#011247", "#007295", "#00a700", "#a5c900", "#915300", "#bf3900",
                   "#969391", "#636363", "#343434", "#000000")

```

```{r}
getwd()

data <- read.csv("./output-data/concept-politicians-allsubjs-none-reagan-nixon-trump.csv", header = FALSE) %>%
  filter(!row_number() %in% c(1, 2, 4)) # remove first row

# rename columns
colnames(data) <- c("ID", "Prompting_condition", "Experiment", "Concept", "Choice1", "Choice2", "Response1", "Response2")

```
### Data formatting

```{r}
# capital case response columns
data$Response1 <- str_to_title(data$Response1)
data$Response2 <- str_to_title(data$Response2)

# recode responses and factorize
data$Concept <- as.factor(data$Concept)
data$Concept <- recode(data$Concept, " a chicken" = "chicken", " a dolphin" = "dolphin", " a finch" = "finch",
                                     " a penguin" = "penguin", " a robin" = "robin", " a salmon" = "salmon",
                                     " a seal" = "seal", " a whale" = "whale", " an ostrich" = "ostrich",
                                     " an eagle" = "eagle", " Abraham Lincoln" = "Lincoln", " Barack Obama" = "Obama",
                                     " Bernie Sanders" = "Sanders", " Donald Trump" = "Trump", " Elizabeth Warren" = "Warren",
                                     " George W. Bush" = "Bush", " Hillary Clinton" = "Clinton", " Joe Biden" = "Biden",
                                     " Richard Nixon" = "Nixon", " Ronald Reagan" = "Reagan")
# not sure what this does...
data$Concept <- factor(data$Concept, levels(data$Concept)[c(3, 5, 1, 10, 11, 4, 6, 7, 2, 8, 9, 12:20)])

# factorize Experiment column (animals vs. politicians)
data$Experiment <- as.factor(data$Experiment)

# make new column for question by combining the two choice options and factorize
data$Question <- paste(as.character(data$Choice1), as.character(data$Choice2))
data$Question <- as.factor(data$Question)

# "We coded each participantâ€™s responses to a single word as a binary vector, corresponding to theforced-choice similarity rating between every other pair of items"
# encode this based on the model's first response
data$ChoiceNumber <- ifelse(as.character(data$Response1) == as.character(data$Choice1), 0, 1)

```


### Calculate participant reliability
```{r}
# .rs.restartR()
tmp <- data %>% 
  group_by(ID, Question, Concept) %>% 
  summarise(Reliability = mean(ChoiceNumber))

tmp$Reliability <- ifelse(tmp$Reliability == 0, 1, ifelse(tmp$Reliability == 1, 1, 0))
data <- merge(data, tmp)

reliability <- data.frame(data$Reliability)
reliability$ID <- data$ID

reliability$lower <- ifelse(data$Reliability,
                            prop.test(sum(data$Reliability), length(data$Reliability))$conf.int[1],
                            prop.test(sum(data$Reliability == 0), length(data$Reliability))$conf.int[1])

reliability$upper <- ifelse(data$Reliability,
                            prop.test(sum(data$Reliability), length(data$Reliability))$conf.int[2],
                            prop.test(sum(data$Reliability == 0), length(data$Reliability))$conf.int[2])

tmp <- reliability %>% group_by(ID) %>% summarise(reliabilityPercent = mean(data.Reliability))
data <- merge(data, tmp)
reliability <- merge(reliability, tmp)

reliability$data.Reliability <- factor(reliability$data.Reliability, levels = c(0, 1), labels = c("Not Reliable", "Reliable"))
```

### Calculate Intersubject Reliability

```{r}
tmp <- data %>% group_by(Question, Concept) %>% summarise(QuestionReliability = mean(ChoiceNumber))
tmp <- tmp %>% group_by(Concept) %>% mutate(ConceptReliability = mean(QuestionReliability))
mean(tmp$QuestionReliability)
```

### Calculate Predicted vs. Actual

This block of code uses "Meta" which is the test of metacognitive agreement: "How many other people out of 10 would agree with you"
[SKIP for initial model analysis]
# ```{r}
# tmp <- data %>% group_by(ID, Question, Concept) %>% summarise(reliabilityMeta = abs(first(Meta) - last(Meta)))
# data <- merge(data, tmp)
# 
# tmp <- data %>% group_by(ID) %>% summarise(metaSD = abs(sd(Meta)))
# data <- merge(data, tmp)
# 
# tmp <- data %>% group_by(Concept, Question, Choice) %>% dplyr::summarise(Actual = n(), Expected = mean(Meta) / 10)
# tmp2 <- data %>% group_by(Concept, Question) %>% dplyr::summarise(Count = n())
# tmp <- merge(tmp, tmp2)
# tmp$Actual <- tmp$Actual / tmp$Count
# data <- merge(data, tmp)
# 
# tmp <- data %>% group_by(Concept, Question, Choice) %>% summarise(Disagreement = abs(mean(Actual) - mean(Expected)))
# data <- merge(data, tmp)
# 
# # Run correlation between predicted and actual responses
# cor.test(data$Meta, data$Actual,  method = "spearman")
# ```


```{r}
alpha <- .16
probs <- rbeta(1000000, alpha, alpha)
agree <- 1 != rbinom(1000000, 2, probs)
prop.table(table(agree))

mean(data$Reliability) # alpha = .16
# mean(subset(data, Experiment %in% c("Animals"))$Reliability) # alpha = .14
mean(subset(data, Experiment %in% c("Politicians"))$Reliability) #alpha = .18

# Write people's responses to CSV for use in the CRP model
responses <- data %>% distinct(ID, Question, Concept, .keep_all = TRUE)
responses <- responses %>% select(Concept, ID, Question, ChoiceNumber)
write.csv(responses, "./output-data/gpt3.5-responses-for-CRP-model-reagan-nixon-trump.csv")
```
```{r}
# Read in main CRP model results
clusteringData <- read.csv("./Chinese Restaurant Model/gpt3.5-ClusteringResults-2.csv")

clusteringData$Concept <- as.factor(clusteringData$Concept)
clusteringData$Concept <- recode(clusteringData$Concept, "a chicken" = "chicken", "a dolphin" = "dolphin", "a finch" = "finch",
                       "a penguin" = "penguin", "a robin" = "robin", "a salmon" = "salmon",
                       "a seal" = "seal", "a whale" = "whale", "an ostrich" = "ostrich", "an eagle" = "eagle",
                       "Abraham Lincoln" = "Lincoln", "Barack Obama" = "Obama",
                       "Bernie Sanders" = "Sanders", "Donald Trump" = "Trump", "Elizabeth Warren" = "Warren",
                       "George W. Bush" = "Bush", "Hillary Clinton" = "Clinton", "Joe Biden" = "Biden",
                       "Richard Nixon" = "Nixon", "Ronald Reagan" = "Reagan")

clusteringData$Concept <- factor(clusteringData$Concept, levels(clusteringData$Concept)[c(3, 5, 6, 7, 11, 12, 14, 15, 17, 20,
                                                                                          1, 2, 4, 8, 9, 10, 13, 16, 18, 19)])

clusteringData$NumberOfPeople <- pmin(100, clusteringData$NumberOfPeople)
clusteringData$NumberOfPeople <- as.factor(clusteringData$NumberOfPeople)
clusteringData$NumberOfTrials <- as.factor(clusteringData$NumberOfTrials)
clusteringData$Alpha <- as.factor(clusteringData$Alpha)
clusteringData$Prior <- as.factor(clusteringData$Prior)
clusteringData$Prior <- recode(clusteringData$Prior, "Simplicity Prior" = "Simplicity", "Uniform Prior" = "Uniform")

numberOfTables <- clusteringData %>% group_by(Concept, NumberOfPeople, Alpha, Prior) %>% summarise(mean = mean(Tables),
                                                                                                   sd = sd(Tables),
                                                                                                   MAPTables = Tables[which.max(Posterior)],
                                                                                                   MAPCHAO = S_Chao1[which.max(Posterior)],
                                                                                                   ProbabilityOfSameTable = ProbabilityOfSameTable[which.max(Posterior)])
numberOfTables <- numberOfTables %>% mutate(probabilityOfOne = pnorm(2, mean, sd))


numberOfTables$Experiment <- ifelse(!grepl("\\b(?=[a-z])", as.character(numberOfTables$Concept), perl = TRUE), "Politicians", "Animals")
numberOfTables$Experiment <- as.factor(numberOfTables$Experiment)
numberOfTables$Prior <- recode(numberOfTables$Prior, "Simplicity Prior" = "Simplicity", "Uniform Prior" = "Uniform")
```

```{r}
ggplot(filter(numberOfTables, NumberOfPeople %in% c("100"), Alpha == "0.16", Prior == "Simplicity", Experiment == "Animals"), aes(y = ProbabilityOfSameTable, x = Concept)) +
  geom_bar(stat = "identity") +
  labs(y = "P of same concept", x = "") +
  ylim(0, 1)

ggplot(filter(numberOfTables, NumberOfPeople %in% c("100"), Alpha == "0.16", Prior == "Simplicity", Experiment == "Politicians"), aes(y = ProbabilityOfSameTable, x = Concept)) +
  geom_bar(stat = "identity") +
  labs(y = "P of same concept", x = "") +
  ylim(0, 1)
```

